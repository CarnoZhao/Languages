{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "using MLDatasets, LinearAlgebra, Statistics, Images\n",
    "\n",
    "train_x, train_y = MNIST.traindata()\n",
    "test_x, test_y = MNIST.testdata()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu(x) = max(0, x)\n",
    "sigmoid(x) = 1 / (1 + exp(-x))\n",
    "relu_derivative(y) = ifelse(y > 0, 1, 0)\n",
    "sigmoid_derivative(y) = y * (1 - y)\n",
    "\n",
    "function random_initialization(layer_dims)\n",
    "    parameters = []\n",
    "    L = length(layer_dims) - 1\n",
    "    for i in 1:L\n",
    "        W = randn(layer_dims[i + 1], layer_dims[i]) * sqrt(2 / layer_dims[i])\n",
    "        b = zeros(layer_dims[i + 1], 1)\n",
    "        push!(parameters, [W, b])\n",
    "    end\n",
    "    parameters\n",
    "end\n",
    "\n",
    "function moment_initialization(parameters)\n",
    "    V = []\n",
    "    for W, b in parameters\n",
    "        \n",
    "\n",
    "function forward(X, parameters)\n",
    "    caches = [X]\n",
    "    A = X\n",
    "    L = length(parameters)\n",
    "    for i in 1:L\n",
    "        W, b = parameters[i]\n",
    "        Z = W * A .+ b\n",
    "        A = ifelse(i == L, sigmoid.(Z), relu.(Z))\n",
    "        push!(caches, A)\n",
    "    end\n",
    "    caches\n",
    "end\n",
    "\n",
    "function backward(Y, parameters, caches)\n",
    "    grads = []\n",
    "    L = length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
