{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using PyPlot;\n",
    "using LinearAlgebra, Statistics, HDF5, Images\n",
    "\n",
    "train_data = read(h5open(\"../../data/train_catvnoncat.h5\"))\n",
    "test_data = read(h5open(\"../../data/test_catvnoncat.h5\"))\n",
    "\n",
    "train_X = Int.(train_data[\"train_set_x\"]) ./ 255\n",
    "train_Y = train_data[\"train_set_y\"]\n",
    "test_X = Int.(test_data[\"test_set_x\"]) ./ 255\n",
    "test_Y = test_data[\"test_set_y\"]\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function initialize_parameters(layer_dims)\n",
    "    parameters = []\n",
    "    L = length(layer_dims) - 1\n",
    "    for i in 1:L\n",
    "        W = randn(layer_dims[i + 1], layer_dims[i]) * 0.05\n",
    "        b = randn(layer_dims[i + 1], 1)\n",
    "        push!(parameters, [W, b])\n",
    "    end\n",
    "    parameters\n",
    "end\n",
    "\n",
    "function L_model_forward(X, parameters)\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = length(parameters)\n",
    "    for i in 1:L\n",
    "        A_prev = A\n",
    "        W, b = parameters[i]\n",
    "        Z = W * A_prev .+ b\n",
    "        A = ifelse(i == L, 1 ./ (1 .+ exp.(-Z)), max.(0, Z))\n",
    "        push!(caches, A)\n",
    "    end\n",
    "    caches\n",
    "end\n",
    "\n",
    "function compute_cost(AL, Y)\n",
    "    cost = -mean(Y .* log.(AL) + (1 .- Y) .* log.(1 .- AL))\n",
    "    cost\n",
    "end\n",
    "\n",
    "function L_model_backward(X, Y, parameters, caches)\n",
    "    grads = []\n",
    "    L = length(parameters)\n",
    "    AL = caches[L]\n",
    "    dA = (AL - Y) ./ (AL .* (1 .- AL))\n",
    "    for i in L:-1:1\n",
    "        if i == 1\n",
    "            A_prev = X\n",
    "        else\n",
    "            A_prev = caches[i - 1]\n",
    "        end\n",
    "        W = parameters[i][1]\n",
    "        dZ = dA .* ifelse(\n",
    "            i == L, \n",
    "            caches[i] .* (1 .- caches[i]),\n",
    "            ifelse.(caches[i] .> 0, 1, 0)\n",
    "            )\n",
    "        dW = dZ * A_prev' ./ size(A_prev)[2]\n",
    "        db = mean(dZ, dims = 2)\n",
    "        dA = W' * dZ\n",
    "        push!(grads, [dW, db])\n",
    "    end\n",
    "    grads\n",
    "end\n",
    "\n",
    "function update_parameters(parameters, grads, learning_rate)\n",
    "    L = length(parameters)\n",
    "    for i in 1:L\n",
    "        parameters[i][1] -= learning_rate .* grads[L - i + 1][1]\n",
    "        parameters[i][2] -= learning_rate .* grads[L - i + 1][2]\n",
    "    end\n",
    "    parameters\n",
    "end\n",
    "\n",
    "function L_layer_model(X, Y, layer_dims; learning_rate = 0.0075, num_iterations = 3000)\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    for i in 1:num_iterations\n",
    "        caches = L_model_forward(X, parameters)\n",
    "        grads = L_model_backward(X, Y, parameters, caches)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if i % 100 == 0\n",
    "            AL = caches[length(caches)]\n",
    "            cost = compute_cost(AL, Y)\n",
    "            println(\"Cost after iteration $(i): $(round(cost, digits = 4))\")\n",
    "        end\n",
    "    end\n",
    "    parameters\n",
    "end\n",
    "\n",
    "function predict(X, parameters)\n",
    "    caches = L_model_forward(X, parameters)\n",
    "    Y_hat = ifelse.(caches[length(caches)] .> 0.5, 1, 0)\n",
    "    Y_hat\n",
    "end\n",
    "\n",
    "function main(train_X, train_Y, test_X, test_Y; num_iterations = 4500, learning_rate = 0.0075)\n",
    "    train_X = reshape(train_X, :, size(train_X)[length(size(train_X))])\n",
    "    train_Y = reshape(train_Y, :, size(train_Y)[length(size(train_Y))])\n",
    "    test_X = reshape(test_X, :, size(test_X)[length(size(test_X))])\n",
    "    test_Y = reshape(test_Y, :, size(test_Y)[length(size(test_Y))])\n",
    "    layer_dims = [size(train_X)[1], 20, 7, 5, size(train_Y)[1]]\n",
    "    parameters = L_layer_model(train_X, train_Y, layer_dims, num_iterations = num_iterations, learning_rate = learning_rate)\n",
    "    train_Y_pred = predict(train_X, parameters)\n",
    "    test_Y_pred = predict(test_X, parameters)\n",
    "    println(\"train accuracy: $(round(mean(train_Y_pred .== train_Y) * 100, digits = 2))%\")\n",
    "    println(\"test accuracy: $(round(mean(test_Y_pred .== test_Y) * 100, digits = 2))%\")\n",
    "    parameters\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 100: 1.3806\n"
     ]
    }
   ],
   "source": [
    "parameters = main(train_X, train_Y, test_X, test_Y);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
